<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script type="text/javascript" src="js/hidebib.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Hai Nguyen</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Hai Nguyen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="icon" type="image/png" href="images/northeastern.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:0%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hai Nguyen</name>
              </p>
              <p>I am a PhD candidate in Computer Science at <a href="https://www.northeastern.edu/">Northeastern University (USA)</a>, jointly advised by <a href="https://www.ccs.neu.edu/home/camato/"> Christopher Amato </a> (<a href="https://llpr.ccs.neu.edu/">LLPR</a> lab) and <a href="https://www2.ccs.neu.edu/research/helpinghands/"> Robert Platt</a> (<a href="https://www2.ccs.neu.edu/research/helpinghands/">The Helping Hands</a> lab).
              I received my M.Sc. degree in Unmanned Aircraft Systems Design from <a href="https://www.southampton.ac.uk/">University of Southampton (UK)</a> as a proud <a href="https://www.chevening.org/">Chevening</a> scholar, and B.Sc. degree in automation engineering (talented program) from <a href="https://en.hust.edu.vn/">Hanoi University of Science and Technology (Vietnam)</a>. My research lies in the interesection <u>robot manipulation</u> and <u>reinforcement learning</u> under <u>partial observability</u>, using the framework of POMDPs.
              Before coming to Northeastern, I have several years working as a flight control engineer for autonomous drones in Vietnam.
              </p>
              <p style="color:red">
                I am activately looking for a full-time robotics research scientist/engineer position in industry. Please feel free to contact me if you have any fit opening at nguyen.hai1@northeastern.edu.
              </p>
              <p style="text-align:center">
                <a href="mailto:nguyen.hai1@northeastern.edu">Email</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=5b9ncWoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/hai-h-nguyen">Github</a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/hai-nguyen-565340152/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/HaiNguy69482974/">Twitter</a>
              </p>
              <!-- <p style="text-align:center">
                <a href="https://twitter.com/HaiNguy69482974" class="twitter-follow-button" data-show-count="false">Follow @HaiNguy69482974</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
              </p> -->
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpg"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <hr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:0px;width:100%;vertical-align:left">
                    <heading>Recent News</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
<!--              <li><strong>[<del><font color="red">Call for Papers</font></del>]</strong> I am co-organizing the Workshop on <a href="https://adv-workshop-2020.github.io/">Adversarial Machine Learning in Computer Vision</a> in CVPR 2020. <del>Please submit your paper <a href="https://cmt3.research.microsoft.com/CVPRamlcv2020">here</a>!</del></li>-->
              <!-- <li><strong><font color="red">[Call for Papers]</font> I am co-organizing the Workshop on <a href="https://eccv20-adv-workshop.github.io/">Adversarial Robustness in the Real World</a> in ECCV 2020. Please submit your paper <a href="https://cmt3.research.microsoft.com/AROW2020">here</a></strong>.</li> -->
              <!-- <li><strong>Two papers [<a href="https://arxiv.org/abs/1904.00979">1</a>, <a href="https://arxiv.org/abs/2004.05682">2</a>] are accepted by ECCV 2020</strong>.</li> -->
              <!-- <li><strong>I am co-organizing the Workshop on <a href="https://adv-workshop-2020.github.io/">Adversarial Machine Learning in Computer Vision</a> in CVPR 2020 <a href="https://www.youtube.com/watch?v=FCTf5MeIBFM&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy">[video]</a></strong>.</li> -->
              <!-- <li><strong>Three papers [<a href="https://arxiv.org/abs/1911.09665">1</a>, <a href="https://arxiv.org/abs/2004.01961">2</a>, <a href="https://arxiv.org/abs/1909.04326">3</a>] are accepted by CVPR 2020</strong>.</li> -->
              <li><strong>[Aug-2023] Our paper <a href="https://openreview.net/forum?id=AnDDMQgM7-">Equivariant Reinforcement Learning under Partial Observability</a> is accepted at <a href="https://corl2023.org/">CoRL-2023</a></strong>.</li>
              <li><strong>[June-2023] Two papers <a href="https://arxiv.org/abs/2307.11954">On-Robot Bayesian Reinforcement Learning for POMDPs</a> and <a href="https://arxiv.org/abs/2306.13872">Learning from Pixels with Expert Observations           </a> are accepted at <a href="https://ieee-iros.org/">IROS-2023</a>. </li>
              <li><strong>[May-2023] I start a research internship in <a href="https://www.omron.com/sinicx/en/">OMRON SINIC X Corporation (OSX)</a> (Tokyo) about soft robots manipulation as a POMDP with <a href="https://www.omron.com/sinicx/en/member/">Masashi Hamaya and Tadashi Kozuno</a></strong>.</li>
              <li><strong>[Sep-2022] Our paper <a href="https://arxiv.org/abs/2211.01991">Leveraging Fully Observable Policies for Learning under Partial Observability</a> is accepted at <a href="https://corl2022.org/">CoRL-2022</a></strong>.</li>
              <li><strong>[Mar-2022] Our paper <a href="https://arxiv.org/abs/2204.00898">Hierarchical Reinforcement Learning under Mixed Observability</a> is accepted at <a href="https://wafr2022.github.io/">The 15th International Workshop on the Algorithmic Foundations of Robotics (WAFR)</a></strong>.</li>
              <!-- <li><strong>[Oct-2021] Our workshop paper <a href="https://arxiv.org/abs/2110.12628">Recurrent Off-policy Baselines for Memory-based Continuous Control</a> is accepted at <a href="https://sites.google.com/view/deep-rl-workshop-neurips2021">Deep Reinforcement Learning Workshop - NeurIPS</a></strong>.</li> -->
              <!-- <li><strong>One paper about hierarchical learning in POMDP at RAL/ICRA (Sep. 2021) </strong>.</li> -->
              <!-- <li><strong>I got 4 intership interviews for Summer 2021 at MERL (2), Bosch Austin (1), and SRI International (1) but failed all of them (March 2021) </strong>.</li> -->
              <li><strong>[Oct-2020] Our paper <a href="https://proceedings.mlr.press/v155/nguyen21a.html">Belief-Grounded Networks for Accelerated Robot Learning under Partial Observability</a> is accepted at <a href="https://sites.google.com/robot-learning.org/corl2020">CoRL 2020</a></strong>.</li>
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:left">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr bgcolor="#ffffd0">
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/abs/2307.11954" style="color: red;">
                    <papertitle> On-Robot Bayesian Reinforcement Learning for POMDPs</papertitle>
                </a>
                <br>
                <strong>Hai Nguyen</strong>, Sammie Katt, Yuchen Xiao, Christopher Amato.
                <br>
                <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<u>IROS</u>)</em>, 2023
                <br>
                <p style="color:  #3369ff;">
                    TLDR: We used the framework of Bayesian Adaptive RL and mixed-observability assumption to quickly learn a planning-based policy directly on hardware.
                  </p>
                <a href="https://www.youtube.com/watch?v=H9xp60ngOes">robot video</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1RCzCY9vHTXbdNjcRmSzHsyj3aOT7Sfgi/view?usp=sharing">poster</a>
            </td>
            <td style="padding:10px;width:35%;vertical-align:middle">
                <img src='images/brl.png' width="200"></div>
            </td>
        </tr>

        <tr bgcolor="#ffffd0">
            <td width="75%" valign="middle">
                <hr>
                <p>
                <a href="https://openreview.net/pdf?id=AnDDMQgM7-" style="color: red;">
                    <papertitle> Equivariant Reinforcement Learning under Partial Observability</papertitle>
                </a>
                <br>
                <strong>Hai Nguyen</strong>, Andrea Baisero, David Klee, Dian Wang, Robert Platt, Christopher Amato.
                <br>

                <em>Conference on Robot Learning (<u>CoRL</u>)</em>, 2023
                <br>
                <p style="color: #3369ff;">
                    TLDR: We leveraged the symmetry in SE(2) using spherical CNNs for memory-based agents to solve a class of symmetric POMDPs.
                  </p>
                <a href="https://github.com/hai-h-nguyen/equi-rl-for-pomdps">code</a> &nbsp/&nbsp
                <a href="https://sites.google.com/view/equi-rl-pomdp">project page</a>
            </td>
            <td style="padding:10px;width:35%;vertical-align:middle">
                <img src='images/equi.png' width="200"></div>
            </td>
        </tr>

        <tr bgcolor="#ffffd0">
            <td width="75%" valign="middle">
                <hr>
                <p>
                <a href="https://arxiv.org/abs/2211.01991" style="color: red;">
                    <papertitle>Leveraging Fully Observable Policies for Learning under Partial Observability</papertitle>
                </a>
                <br>
                <strong>Hai Nguyen</strong>, Andrea Baisero, Dian Wang, Christopher Amato, Robert Platt.
                <br>
                <em>Conference on Robot Learning (<u>CoRL</u>)</em>, 2022
                <br>
                <p style="color: #3369ff;">
                    TLDR: We proposed a method to learn POMDP policies under the guidance of MDP expert policies.
                  </p>
                <a href="https://github.com/hai-h-nguyen/cosil-corl22">code</a> &nbsp/&nbsp
                <a href="https://sites.google.com/view/cosil-corl22">project page</a>
            </td>
            <td style="padding:10px;width:35%;vertical-align:middle">
                <img src='images/cosil.png' width="150"></div>
            </td>
        </tr>

        <tr bgcolor="#ffffd0">
          <td width="75%" valign="middle">
            <hr>
              <p>
              <a href="https://arxiv.org/pdf/2204.00898.pdf" style="color: red;">
                  <papertitle>Hierarchical Reinforcement Learning under Mixed Observability</papertitle>
              </a>
              <br>
              <strong>Hai Nguyen</strong>*, Zhihan Yang*, Andrea Baisero, Xiao Ma, Robert Platt, Christopher Amato.
              <br>
              <em>International Workshop on the Algorithmic Foundations of Robotics (<u>WAFR</u>)</em>, 2022
              <br>
              <p style="color: #3369ff;">
                TLDR: We proposed a hierarchical agent addressing a class of POMDPs that only needs to works with partial observability on the top level.
              </p>
              <a href="https://sites.google.com/view/hilmo-wafr">project page</a>
          </td>
          <td style="padding:10px;width:35%;vertical-align:middle">
            <img src='images/hilmo.png' width="250"></div>
            </td>
        </tr>

       
        <tr bgcolor="#ffffd0">
          <td width="75%" valign="middle">
            <hr>
              <p>
              <a href="https://proceedings.mlr.press/v155/nguyen21a.html" style="color: red;">
                  <papertitle>Belief-Grounded Networks for Accelerated Robot Learning under Partial Observability</papertitle>
              </a>
              <br>
              <strong>Hai Nguyen</strong>*, Brett Daley*, Xinchao Song, Christopher Amato, Robert Platt.
              <br>
              <em>Conference on Robot Learning (<u>CoRL</u>),</em> 2020
              <br>
              <p style="color: #3369ff;">
                TLDR: We proposed auxiliary losses to leverage belief states during training to improve the learning efficiency of actor-critic agents.
              </p>
              <a href="https://github.com/hai-h-nguyen/belief-grounded-network">code</a> &nbsp/&nbsp
              <a href="https://sites.google.com/view/bgn-pomdp">project page</a>
          </td>
          <td style="padding:10px;width:70%;vertical-align:middle">
            <img src='images/bgn.png' width="250"></div>
                </td>
          </tr>

        </tbody></table>
        <hr>
        
        
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Professional Service</heading>
                </td>
            </tr>
        </tbody></table> -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
        
        <!-- </tbody></table> -->
        <!-- <hr> -->


<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Service</heading>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->
<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle"><img src="old-images/cvf.jpg"></td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>-->
<!--              <br>-->
<!--              <br>-->
<!--              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:left">
            <heading>Reviewers</heading>
            </td>
        </tr>
        </tbody></table>

        <tr>
            <td width="75%" valign="middle">
                <p>
                <em><strong>ICRA</strong> (2021, 2024), </em>
                <em><strong>RAL</strong> (2022, 2023), </em>
                <em><strong>IROS</strong> (2022, 2023), </em>
                <em><strong>RO-MAN</strong> (2022)</em>
                </p>
                <!-- <div class="paper" id="nguyen2019hindsight">
                    <a href="https://ara.cse.unr.edu/wp-content/uploads/2014/12/ICDL2019_Hai.pdf">paper</a> /
                    <a href="data/nguyen2019hindsight.bib">bibtex</a>
                </div> -->
            </td>
        </tr> <!--nguyen2019hindsight--> 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <!-- <td width=50% align="center">
              <a href="https://clustrmaps.com/site/1b2nv"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=_s2_OduoO888ugvX-pYCsciaAlSir2c84N9WH4N3AmQ&cl=ffffff" /></a>
            </td> -->
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">Style from <a href="https://cihangxie.github.io/cihangxie.github.io/">Cihang Xie</a></p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<!-- Google Analytics -->
<!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script> -->
<!-- End Google Analytics -->

</body>

</html>
